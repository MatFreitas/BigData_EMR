{
  "metadata": {
    "name": "ProjetoFinal",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import NaiveBayes\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd \u003d sc.textFile(\u0027s3://megadados-alunos/dados/all_reviews_clean_tsv/\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd.take(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd \u003d  rdd.cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_response \u003d rdd.map(lambda x: x.split(\u0027\\t\u0027)) "
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_response.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nreviews\u003d rdd.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nreviews"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_clients \u003d rdd_response \\\n    .map(lambda x: x[1]).distinct()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_clients.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_products \u003d rdd_response \\\n    .map(lambda x: x[3]).distinct()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_products.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\nratings\u003drdd_response.map(lambda x: x[7]).countByValue().items()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nratings"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nspark \u003d SparkSession.builder.appName(\u0027ReviewClassifier\u0027).getOrCreate()\n# Load data and rename column\ndf_desafio \u003d spark.read.option(\"header\", \"false\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\") \\\n    .withColumnRenamed(\"_c1\", \"customer_id\") \\\n    .withColumnRenamed(\"_c3\", \"product_id\") \\\n    .withColumnRenamed(\"_c5\", \"product_title\") \\\n    .withColumnRenamed(\"_c7\", \"star_rating\")"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_clientes\u003ddf_desafio.select(\"customer_id\",\"product_id\", \"product_title\", \"star_rating\")\ndf_clientes.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_desafioCostumer\u003d df_clientes.groupBy(\u0027customer_id\u0027).count()\ndf_desafioCostumer.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_clientesUnicos \u003d df_desafioCostumer.filter(\"count \u003d\u003d 1\")\ndf_clientesUnicos.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_desafioJoin \u003d df_clientesUnicos.join(df_clientes, df_clientesUnicos.customer_id \u003d\u003d df_clientes.customer_id, \u0027inner\u0027).select(df_clientesUnicos.customer_id, df_clientes.product_id,df_clientes.product_title, df_clientes.star_rating)    \ndf_desafioJoin.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.types import DoubleType, IntegerType, DateType\ndf_desafioJoin[\u0027star_rating\u0027].cast(IntegerType())"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import mean as mean_\n\ndf_mean \u003d df_desafioJoin.groupBy(\u0027product_id\u0027).agg(mean_(\u0027star_rating\u0027))\ndf_mean.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_mean \u003d df_mean.withColumnRenamed(\"avg(star_rating)\", \"mean_rating\")\ndf_mean.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_desafioProdutos\u003d df_desafioJoin.groupBy(\u0027product_id\u0027).count()\ndf_desafioProdutos.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_produtos10 \u003d df_desafioProdutos.filter(\"count \u003e 10\")\ndf_produtos10.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_final \u003d df_produtos10.join(df_mean, df_produtos10.product_id \u003d\u003d df_mean.product_id, \u0027inner\u0027).select(df_produtos10.product_id, df_mean.mean_rating)    \ndf_final.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_finalReview \u003d df_final.orderBy(\"mean_rating\",ascending\u003dFalse)\ndf_finalReview.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_desafioConcluido \u003d df_finalReview.join(df_desafioJoin, df_finalReview.product_id \u003d\u003d df_desafioJoin.product_id, \u0027inner\u0027).select(df_finalReview.product_id, df_desafioJoin.product_title, df_finalReview.mean_rating)    \ndf_desafioConcluido.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_desafioFinal \u003d df_desafioConcluido.orderBy(\"mean_rating\",ascending\u003dFalse)\ndf_desafioFinal.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\u0027ReviewClassifier\u0027).getOrCreate()\n# Load data and rename column\ndf \u003d spark.read.option(\"header\", \"false\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\") \\\n    .withColumnRenamed(\"_c1\", \"customer_id\") \\\n    .withColumnRenamed(\"_c6\", \"product_category\") \\\n    .withColumnRenamed(\"_c7\", \"star_rating\") \\\n    .withColumnRenamed(\"_c8\", \"helpful_votes\") \\\n    .withColumnRenamed(\"_c13\", \"review_body\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_bot\u003ddf.select(\"customer_id\",\"product_category\", \"star_rating\", \"helpful_votes\")"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_bot.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_costumer\u003d df_bot.groupBy(\u0027customer_id\u0027).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_costumer.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botReview \u003d df_costumer.orderBy(\"count\",ascending\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botReview.show(50)"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botReview.describe([\u0027count\u0027]).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botReview.select(\"count\").summary().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botReview.summary([\"99%\", \"99.6%\", \"99.8%\", \"99.9%\", \"99.95%\", \"99.96%\", \"99.97%\", \"99.98%\", \"99.99%\", \"max\"]).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_bots \u003d df_botReview.filter(\"count \u003e 250\")"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_bots.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_bots.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botsCategory \u003d df_bots.join(df_bot, df_bots.customer_id \u003d\u003d df_bot.customer_id, \u0027inner\u0027).select(df_bots.customer_id, df_bot.product_category, df_bot.star_rating, df_bot.helpful_votes)    "
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botsCategory.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_helpful\u003d df_botsCategory.groupBy(\u0027helpful_votes\u0027).count()\ndf_helpful.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botVotes \u003d df_helpful.orderBy(\"count\",ascending\u003dFalse)\ndf_botVotes.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botVotes2 \u003d df_helpful.orderBy(\"helpful_votes\",ascending\u003dFalse)\ndf_botVotes2.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_products\u003d df_botsCategory.groupBy(\u0027product_category\u0027).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_products.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botProducts \u003d df_products.orderBy(\"count\",ascending\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botProducts.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botRatings\u003d df_botsCategory.groupBy(\u0027star_rating\u0027).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botRatings.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botStarRatings \u003d df_botRatings.orderBy(\"count\",ascending\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_botStarRatings.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_columns\u003ddf.select(\"star_rating\",\"review_body\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_nv\u003ddf_columns.dropna()"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_nv.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import when, lit\n\n\ndf_rating_label\u003d  df_nv.withColumn(\"label_rating\", \\\n   when((df.star_rating \u003c\u003d 3), lit(\"negativo\")) \\\n     .when((df.star_rating \u003d\u003d 4), lit(\"neutro\")) \\\n     .otherwise(lit(\"positivo\")) \\\n  )"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_rating_label.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nstages \u003d []\n\nregexTokenizer \u003d RegexTokenizer(inputCol\u003d\"review_body\", outputCol\u003d\"tokens\", pattern\u003d\"\\W+\")\nstages +\u003d [regexTokenizer]\n\ncv \u003d CountVectorizer(inputCol\u003d\"tokens\", outputCol\u003d\"token_features\", minDF\u003d2.0)#, vocabSize\u003d3, minDF\u003d2.0\nstages +\u003d [cv]\n\nindexer \u003d StringIndexer(inputCol\u003d\"label_rating\", outputCol\u003d\"label\")\nstages +\u003d [indexer]\n\nvecAssembler \u003d VectorAssembler(inputCols\u003d[\u0027token_features\u0027], outputCol\u003d\"features\")\nstages +\u003d [vecAssembler]\n\n[print(\u0027\\n\u0027, stage) for stage in stages]\n"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml import Pipeline\n\npipeline \u003d Pipeline(stages\u003dstages)\ndata \u003d pipeline.fit(df_rating_label).transform(df_rating_label)"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntrain, test \u003d data.randomSplit([0.7, 0.3], seed \u003d 2018)"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.classification import NaiveBayes\n\nnb \u003d NaiveBayes(smoothing\u003d1.0, modelType\u003d\"multinomial\")\nmodel \u003d nb.fit(train)\npredictions \u003d model.transform(test)\npredictions.select(\"label\", \"prediction\", \"probability\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\naccuracy \u003d evaluator.evaluate(predictions)\nprint (\"Model Accuracy: \", accuracy)"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid \u003d ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.5, 2.0]).build()\ncvEvaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\n\ncv \u003d CrossValidator(estimator\u003dnb, estimatorParamMaps\u003dparamGrid, evaluator\u003dcvEvaluator)\ncvModel \u003d cv.fit(train)\n\ncvPredictions \u003d cvModel.transform(test)\n\nevaluator.evaluate(cvPredictions)"
    }
  ]
}